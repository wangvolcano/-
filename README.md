主要是整理之前看过的东西，为找工作做准备，按照复习思路，以博客为主
# 数据结构
## 一.排序算法

（一）[八大排序算法Python版本](https://zhuanlan.zhihu.com/p/25074334)
（二）[快速排序](http://yshblog.com/blog/170)

# 机器学习
## 一、特征处理部分
（一）[特征选择](https://www.cnblogs.com/pinard/p/9032759.html)
（二）[特征表达](https://www.cnblogs.com/pinard/p/9061549.html)
（三）[特征预处理](https://www.cnblogs.com/pinard/p/9093890.html)

博客下面的评论回答还是相当不错的，有蛮多经验

## 损失函数
[各种损失函数](https://www.jianshu.com/p/477a8c1cb05d)  
[损失函数对比](https://blog.csdn.net/u010976453/article/details/78488279)
## 各种下降方法
[三种梯度下降法](https://zhuanlan.zhihu.com/p/25765735)
# 竞赛
[GBDT、XGBOOST、LightGBM比较](https://marian5211.github.io/2018/03/12/%E3%80%90%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%91gbdt-xgboost-lightGBM%E6%AF%94%E8%BE%83/)

[集成学习之Adaboost算法原理小结](https://www.cnblogs.com/pinard/p/6133937.html)

[梯度提升树（GBDT）原理小结](https://www.cnblogs.com/pinard/p/6140514.html)

[LightGBM相对于GBDT的优点](https://www.msra.cn/zh-cn/news/features/lightgbm-20170105)

[GBDT和RF的参数调优](https://cloud.tencent.com/developer/article/1087035)

[GBDT算法流程、特征选择、特征构建和分类](https://www.cnblogs.com/ModifyRong/p/7744987.html)

## 公式推导

[LR逻辑回归的推导](https://zhuanlan.zhihu.com/p/44591359)  
(1)[LR的并行化](https://blog.csdn.net/qq_32742009/article/details/81839071)

[XGBoost公式的推导](https://blog.csdn.net/yangxudong/article/details/53872141)  

[SVM公式的推导](https://www.jianshu.com/p/3531bb9dd658)  

# 面试经验

[为什么要把连续特征离散化](https://www.zhihu.com/question/31989952)  
[SVM常考细节](https://blog.csdn.net/szlcw1/article/details/52259668)  
[朴素贝叶斯常见面试题](https://www.cnblogs.com/zhibei/p/9394758.html)  
[聚类常用面试题](https://blog.csdn.net/cppjava_/article/details/71249209)  
[朴素贝叶斯算法思路](https://cloud.tencent.com/developer/article/1368310)  
[L1和L2正则化](http://izhaoyi.top/2017/09/15/l1-l2/)  [代价函数和正则化](https://blog.csdn.net/meyh0x5vDTk48P2/article/details/79752784)  
[AUC和ROC](https://blog.csdn.net/u013385925/article/details/80385873)



# NLP项目
(1) [word2vec的实现](https://github.com/pakrchen/text-antispam/tree/master/word2vec) (2) [负采样个数解释](https://zhuanlan.zhihu.com/p/39684349) (3) [深度学习中的激活函数和梯度消失](https://www.cnblogs.com/willnote/p/6912798.html) (4) [激活函数的必要条件是什么](https://www.zhihu.com/question/67366051) 

# 推荐系统深度学习
(1)[CTR预估算法之FM, FFM, DeepFM及实践](https://blog.csdn.net/John_xyz/article/details/78933253)  

(2)[Facebook的CTR算法，GBDT+LR的源头](https://zhuanlan.zhihu.com/p/57987311)  

(3)[阿里深度兴趣网络DIN 推荐系统的注意力机制](https://zhuanlan.zhihu.com/p/51623339)  

(4)[YouTube深度推荐系统DNN](https://zhuanlan.zhihu.com/p/52169807) [YouTube深度推荐系统的细节](https://zhuanlan.zhihu.com/p/52504407) [用深度学习DNN构建推荐系统](https://zhuanlan.zhihu.com/p/25343518) 

(5)[Embbeding从word2vec到item2vec](https://zhuanlan.zhihu.com/p/53194407)  

(6)[Wide & Deep Learning](https://blog.csdn.net/google19890102/article/details/78171283)  

(7)[FM算法解析](https://zhuanlan.zhihu.com/p/37963267)

# 深度学习
(1) [Softmax函数的特点与作用](https://www.zhihu.com/question/23765351)
